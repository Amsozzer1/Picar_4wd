{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 37 images belonging to 5 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29 images belonging to 5 classes.\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.6360 - accuracy: 0.0500 - val_loss: 1.5286 - val_accuracy: 0.4500\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 1.2440 - accuracy: 0.4706 - val_loss: 1.2191 - val_accuracy: 0.4000\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 1.3220 - accuracy: 0.1765 - val_loss: 1.1169 - val_accuracy: 0.6500\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 1.2170 - accuracy: 0.6471 - val_loss: 1.4024 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 1.1987 - accuracy: 0.5294 - val_loss: 1.2287 - val_accuracy: 0.6000\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.9220 - accuracy: 0.6471 - val_loss: 1.0221 - val_accuracy: 0.7000\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 1.0405 - accuracy: 0.6000 - val_loss: 1.0973 - val_accuracy: 0.6000\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 1.1482 - accuracy: 0.5500 - val_loss: 1.1949 - val_accuracy: 0.6000\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 1.2394 - accuracy: 0.4706 - val_loss: 1.1853 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 1.0170 - accuracy: 0.5500 - val_loss: 1.2796 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 407ms/step - loss: 0.8433 - accuracy: 0.7000 - val_loss: 1.2528 - val_accuracy: 0.5500\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 1.7970 - accuracy: 0.3529 - val_loss: 1.4276 - val_accuracy: 0.5500\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 1.1048 - accuracy: 0.5294 - val_loss: 1.4177 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 1.1819 - accuracy: 0.4706 - val_loss: 1.2944 - val_accuracy: 0.5500\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 1.2655 - accuracy: 0.5500 - val_loss: 1.4235 - val_accuracy: 0.4000\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 1.2197 - accuracy: 0.5882 - val_loss: 1.3631 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 1.2301 - accuracy: 0.4118 - val_loss: 1.4091 - val_accuracy: 0.4500\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 1.2495 - accuracy: 0.5294 - val_loss: 1.2826 - val_accuracy: 0.5500\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 1.1055 - accuracy: 0.6000 - val_loss: 1.0452 - val_accuracy: 0.6500\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 1.0705 - accuracy: 0.5500 - val_loss: 1.0542 - val_accuracy: 0.5500\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 1.0404 - accuracy: 0.5294 - val_loss: 1.5208 - val_accuracy: 0.4500\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 1.2203 - accuracy: 0.5500 - val_loss: 1.5863 - val_accuracy: 0.5000\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 1.0707 - accuracy: 0.4118 - val_loss: 1.0191 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 412ms/step - loss: 1.1742 - accuracy: 0.5500 - val_loss: 1.4614 - val_accuracy: 0.5000\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 0.9750 - accuracy: 0.6500 - val_loss: 1.1495 - val_accuracy: 0.5500\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 1.0761 - accuracy: 0.5500 - val_loss: 1.1545 - val_accuracy: 0.6000\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 1.0958 - accuracy: 0.5294 - val_loss: 1.4219 - val_accuracy: 0.5500\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 1.0657 - accuracy: 0.5000 - val_loss: 1.3571 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 1.0171 - accuracy: 0.5294 - val_loss: 1.6646 - val_accuracy: 0.4000\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 1.2558 - accuracy: 0.4706 - val_loss: 1.3018 - val_accuracy: 0.6000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.4524 - accuracy: 0.5172\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4524457454681396, 0.517241358757019]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Set the directory where your data is located\n",
    "base_dir = 'C:/Users/amsoz/OneDrive/Desktop/DATA_SET'\n",
    "\n",
    "# Directories for your training, validation, test data\n",
    "train_dir = os.path.join(base_dir, 'train')  # Ensure you have a train directory with subfolders for each class\n",
    "validation_dir = base_dir+\"/val\"  # Ensure you have a validation directory with subfolders for each class\n",
    "\n",
    "total_train_samples = sum([len(files) for r, d, files in os.walk(train_dir)])\n",
    "total_validation_samples = sum([len(files) for r, d, files in os.walk(validation_dir)])\n",
    "# Set batch size\n",
    "batch_size = 20\n",
    "\n",
    "# Image Data Generator with Augmentation for Training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Image Data Generator for Validation (No Augmentation)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Configure the Train and Validation Generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'  # 'categorical' for multi-class classification\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Model Architecture\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dropout(0.5),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(5, activation='softmax')  # 5 units for 5 classes\n",
    "])\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the Model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=total_train_samples // batch_size,  # Ensure proper step size\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=total_validation_samples // batch_size  # Ensure proper step size\n",
    ")\n",
    "\n",
    "# Model Evaluation\n",
    "model.evaluate(validation_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
